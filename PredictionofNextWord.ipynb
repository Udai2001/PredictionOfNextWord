{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhwKc7Du7lQORpIjoHLBfg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Udai2001/PredictionOfNextWord/blob/main/PredictionofNextWord.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "mTHeiafwT4Mb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/A.txt'\n",
        "with open(data_path, 'r') as file:\n",
        "    text_data = file.read()"
      ],
      "metadata": {
        "id": "NzXYqsc4Viuv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text_data])\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "jIJVtXSwVrTg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for line in text_data.split('\\n'):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "cRAInoecVusV"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n"
      ],
      "metadata": {
        "id": "CNI_lZt2VzDX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictors, label = input_sequences[:, :-1], input_sequences[:, -1]"
      ],
      "metadata": {
        "id": "gS1A1iQJV3MJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "iffPdmeeV6X4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(predictors, label, epochs=25, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey-ddoB8V9mK",
        "outputId": "f7bb23cd-ce82-4ce4-c775-f7b3d84bde8a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "73/73 [==============================] - 10s 88ms/step - loss: 6.2207\n",
            "Epoch 2/25\n",
            "73/73 [==============================] - 8s 114ms/step - loss: 5.8071\n",
            "Epoch 3/25\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 5.6994\n",
            "Epoch 4/25\n",
            "73/73 [==============================] - 8s 115ms/step - loss: 5.5877\n",
            "Epoch 5/25\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 5.4859\n",
            "Epoch 6/25\n",
            "73/73 [==============================] - 8s 115ms/step - loss: 5.3931\n",
            "Epoch 7/25\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 5.2825\n",
            "Epoch 8/25\n",
            "73/73 [==============================] - 8s 115ms/step - loss: 5.1424\n",
            "Epoch 9/25\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 4.9873\n",
            "Epoch 10/25\n",
            "73/73 [==============================] - 8s 115ms/step - loss: 4.8100\n",
            "Epoch 11/25\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 4.6320\n",
            "Epoch 12/25\n",
            "73/73 [==============================] - 8s 115ms/step - loss: 4.4532\n",
            "Epoch 13/25\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 4.2790\n",
            "Epoch 14/25\n",
            "73/73 [==============================] - 8s 116ms/step - loss: 4.1113\n",
            "Epoch 15/25\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 3.9461\n",
            "Epoch 16/25\n",
            "73/73 [==============================] - 9s 117ms/step - loss: 3.7895\n",
            "Epoch 17/25\n",
            "73/73 [==============================] - 7s 90ms/step - loss: 3.6375\n",
            "Epoch 18/25\n",
            "73/73 [==============================] - 8s 117ms/step - loss: 3.4942\n",
            "Epoch 19/25\n",
            "73/73 [==============================] - 7s 92ms/step - loss: 3.3495\n",
            "Epoch 20/25\n",
            "73/73 [==============================] - 8s 113ms/step - loss: 3.2099\n",
            "Epoch 21/25\n",
            "73/73 [==============================] - 7s 96ms/step - loss: 3.0710\n",
            "Epoch 22/25\n",
            "73/73 [==============================] - 8s 107ms/step - loss: 2.9419\n",
            "Epoch 23/25\n",
            "73/73 [==============================] - 7s 101ms/step - loss: 2.8136\n",
            "Epoch 24/25\n",
            "73/73 [==============================] - 8s 104ms/step - loss: 2.6845\n",
            "Epoch 25/25\n",
            "73/73 [==============================] - 8s 108ms/step - loss: 2.5565\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf0fb9b160>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(seed_text):\n",
        "    seed_text = seed_text.lower()\n",
        "    seed_text_sequence = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    seed_text_sequence = pad_sequences([seed_text_sequence], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = np.argmax(model.predict(seed_text_sequence), axis=-1)[0]\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    return output_word"
      ],
      "metadata": {
        "id": "TvxsC0BOWDrL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = \"I am\"\n",
        "next_word = predict_next_word(seed)\n",
        "print(\"Seed Text:\", seed)\n",
        "print(\"Predicted Next Word:\", next_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avNVlpueWPAr",
        "outputId": "51f31a35-f2a5-4f98-f9c6-596ce5c188de"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 648ms/step\n",
            "Seed Text: I am\n",
            "Predicted Next Word: good\n"
          ]
        }
      ]
    }
  ]
}